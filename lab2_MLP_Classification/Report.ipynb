{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0081d975-63e0-49e6-b0d7-a597288d6423",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "Summary your findings and motivate your choice of approach. A better motivation show your understanding of the lab. Dont forget to include the result from part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c7c81-20d8-48f8-85ce-e25d78cf81f1",
   "metadata": {},
   "source": [
    "**Name:** \\\n",
    "**Date:** \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab we've explored capabilities of NNs in different machine learning spheres\n",
    "\n",
    "## Result\n",
    "\n",
    "### Task 1\n",
    "\n",
    "1) The results from plotting were different every time. I would assume that it is due to the nature of dataset, as it generates on every notebook rerun. Howeve, I think that 1 node is not enough for desired accuracy. Because, on every rerun results were drastically different, which concludes that our NN model was not reliable enough.\n",
    "\n",
    "### Task 2\n",
    "\n",
    "1) I was able to retrieve 71% accuracy on dataset. It is due to the increased dataset (from task formulation I assumed that I can increase the validation dataset). I find it strange that by increasing validation dataset I was able to get higher accuracy\n",
    "\n",
    "2) I've used 1000 nodes and got 86%. Increasing higher was time consuming. Also, more nodes we add - more accuracy we obtain, but number of nodes must grow exponentialy higher. Thus, I would assume that anything higher than 2000 nodes will have accuracy around 95%\n",
    "\n",
    "3) The loss dropped drastically, about twice as much (from 0.6 to 0.4).\n",
    "**I found out that we must have used the tensorboard. I found out to late (its 15 mins until deadline) thus I did not include it**\n",
    "\n",
    "4) I did not record the most optimal amount, but from numerous test I assume that 50 to 100 is more or less optimal. After 100, it starts to overfitt and fail on validation\n",
    "\n",
    "5) Tests with 20 to 50 nodes were accurate and time efficient enough\n",
    "\n",
    "### Task 3\n",
    "\n",
    "1) Overfitting may be caused by various reasons. One of them is noise. We explicitly did not include noise in this task\n",
    "\n",
    "2) For this case 50 nodes were enough. I've trained further with 100, 400 and 1000. While they showed improvement, this improvement was insignificant. And as nodes grew, the time consumptions also grew\n",
    "\n",
    "3) The smallest one performed the best, which is 0.001. Loss grew with l2 and reached 1 with 0.09 l2 value.\n",
    "\n",
    "### Task 4\n",
    "\n",
    "1) For the first task I went with nodes from previous tasks and more smoothed l2. The task was time consuming, thus remains unfinished\n",
    "\n",
    "2) The code is done, however I did not finish this part either. I think I will need to finish it and submit for late submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
